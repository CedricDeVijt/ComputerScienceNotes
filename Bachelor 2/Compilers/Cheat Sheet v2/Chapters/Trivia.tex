% DONE

\section{Trivia}
\textbf{Q:} Advantage of automata-based scanners over hand-built scanners: They require less coding effort.
\textbf{Q:} Advantage of hand-built scanners over automata-based scanners: They can go beyond regular languages.
\textbf{Q:} If you are implementing an LL(k) parser based on a given grammar, which version of recursion should you favor when manipulating or rewriting the grammar? Right recursion, LL parsers work top-down, predicting which production to use by looking ahead at the next k tokens. Left recursion causes problems for LL parsers because it leads to infinite recursion during parsing.
\textbf{Q:} LLVM intermediate representation language: True: The number of registers is unlimited, The code has to be in SSA: single static assignment, Jumps can only target the start of a basic block. False: Basic blocks can end without a terminator
\textbf{Q:} Argue that the exact versions of type checking and reachability analysis are in fact undecidable. Exact type checking and reachability analysis are undecidable because they reduce to the halting problem. For type checking, determining if a program’s type is exactly correct requires predicting all possible execution paths, which may not terminate, akin to deciding if a Turing machine halts. Similarly, exact reachability analysis involves determining whether a program state is reachable, which also requires solving the halting problem, as it involves predicting if a computation leads to a specific state. Since the halting problem is undecidable, both tasks are undecidable in their exact forms.
\textbf{Q:} Context free grammar for a language L on $\Sigma$. For all words $w \in \sigma^*$, we can use the grammar to determine whether $w \in L$ in time: polynomial in $ \vert w \vert $: CYK (Cocke–Younger–Kasami) algorithm: Runs in $O(n^3)$ time where $n = \vert w \vert$, assuming the grammar is in Chomsky Normal Form.
\textbf{Q:} Suppose we are given a grammar (not necessarily context free!) for a language L on $\Sigma$. For all words $w \in \sigma^*$, we can use the grammar to determine whether $w \in L$ in time: nope, that is an undecidable problem: For a general grammar (not necessarily context-free), the problem of determining whether a word \( w \in L \) is undecidable. This is because general grammars correspond to Turing machines, and the membership problem for languages generated by unrestricted grammars is equivalent to the halting problem, which is undecidable. There is no algorithm that can decide, for all words \( w \in \Sigma^* \), whether \( w \in L \) in a finite amount of time.
\textbf{Q:} Suppose we are given a deterministic finite automaton with state set Q for a language L on $\Sigma$. For all words $w \in \sigma^*$, we can use the automaton to determine whether $w \in L$ in time: $O( \vert w \vert )$: A deterministic finite automaton (DFA) processes an input word $ w $ by transitioning between states for each symbol in $ w $. Since the state set $ Q $ is fixed, each symbol is processed in constant time, $ O(1) $, by looking up the transition in the DFA's transition table. For a word of length $  \vert w \vert  $, the DFA makes $  \vert w \vert  $ transitions, resulting in a total time complexity of $ O( \vert w \vert ) $.
\textbf{Q:} How can we make sure the sequence 'true' is always deamed a contant and not a string? Define "true" as a reserved keyword or boolean literal in the lexer rules, distinct from string literals (e.g., quoted strings like "true").
\textbf{Q:} What is the longest match principle?
A: The principle states that when there is a choice between several possible matches during tokenization, the lexer should choose the longest possible match that forms a valid token.
\textbf{Q:} Give an arithmetic-expression tree such that the minimal number of registers required to evaluate it is exactly 7: We need to ensure that the computation's register usage peaks at 7, meaning at least one point in the evaluation requires 7 registers to hold intermediate results, and no evaluation requires more. $((((((a + b) + c) + d) + e) + f) + g)$
\textbf{Q:} How do you enforce precedence in a grammar? Enforced by structuring the grammar rules to reflect the desired hierarchy of operations, typically using separate non-terminals for each precedence level. For example, in a simple arithmetic grammar, you define rules like Expr -> Expr + Term | Term and Term -> Term * Factor | Factor to ensure multiplication (*) is evaluated before addition (+).